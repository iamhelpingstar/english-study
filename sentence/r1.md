A diagonal matrix just scales the coordinates by the diagonal entries, so we can take our eigenvectors to be the unit coordinate vectors e1, e2, e3.

대각 행렬은 대각선 항목에 의해 좌표를 스케일링하기 때문에, 우리는 고유벡터를 단위 좌표 벡터 e1, e2, e3로 취급할 수 있습니다.

A has only one linearly independent eigenvector, so by the "only if" part of the diagonalization theorem, A is not diagonalizable.

A는 오직 하나의 선형 독립적인 고유벡터만을 가지므로, 대각화 정리의 "only if" 부분에 따라 A는 대각화될 수 없습니다.

Suppose you measure a data point x which you know for theoretical reasons must lie on a plane spanned by two vectors u and v.

이론적인 이유로 두 벡터 u와 v에 의해 span된 평면 위에 있어야 하는 데이터 포인트 x를 측정한다고 가정해 보세요.

The null space of the m x n matrix you get by "turning them sideways and smooshing them together."

"옆으로 돌리고 함께 눌러붙이는" 방식으로 얻은 m x n 행렬의 null space입니다.

Assigning a Tensor doesn’t have such effect. This is because one might want to cache some temporary state, like last hidden state of the RNN, in the model. If there was no such class as Parameter, these temporaries would get registered too.

텐서를 할당하는 것은 이러한 효과가 없습니다. 이는 모델에 RNN의 마지막 hidden state와 같은 일시적인 상태를 캐시하고 싶을 수 있기 때문입니다. 만약 Parameter와 같은 클래스가 없다면, 이러한 임시 상태들도 등록될 것입니다.

It is a pain to verify using the row-column rule! Much easier: use associativity of linear transformations:

행-열 규칙을 사용하여 검증하는 것은 고통스럽습니다! 훨씬 쉬운 방법은 선형 변환의 결합성을 사용하는 것입니다:

You have to learn (and should understand, since it's well within what we've covered in class so far.)

배워야 합니다 (그리고 이해해야 합니다, 왜냐하면 그것은 우리가 지금까지 수업에서 다룬 범위 안에 잘 들어맞기 때문입니다.)

Information Retrieval investigates: Find relevant docs in a small and trust set

정보 검색은 다음을 조사합니다: 작고 신뢰할 수 있는 집합에서 관련 문서를 찾기

Leads to random suffer model:

random suffer 모델로 이어집니다:

PageRank = limiting probability of being at a page at any point in time.

PageRank = 시간상 어느 지점에서든 페이지에 있을 확률의 극한값입니다.

The tendency to anthropomorphize AI systems is one of the big obstacles in the way of actually trying to understand how AI might impact the world in the future.

AI 시스템에 인간화 경향을 부여하는 것은 실제로 AI가 미래에 세계에 어떤 영향을 미칠 수 있는지 이해하려는 노력에 있어 큰 장애물 중 하나입니다.

This allows to make the most of the accelerators and enables the algorithms to work with large learned environment models parameterized by deep neural networks.

이를 통해 가속기를 최대한 활용할 수 있고, 딥 뉴럴 네트워크로 매개변수화된 큰 학습 환경 모델과 함께 알고리즘이 작동할 수 있게 합니다.

One thing that should be learned from the bitter lesson is the great power of general purpose methods, of methods that continue to scale with increased computation even as the available computation becomes very great. The two methods that seem to scale arbitrarily in this way are search and learning.

쓰라린 교훈에서 배워야 할 한 가지는 범용 방법의 강력한 힘입니다. 사용 가능한 계산량이 매우 많아지더라도 계산 증가에 따라 계속 확장되는 방법들이 있습니다. 이런 식으로 임의로 확장되는 것처럼 보이는 두 가지 방법은 검색과 학습입니다.

However, using search algorithms in combination with deep neural networks requires efficient implementations, typically written in fast compiled languages; this can come at the expense of usability and hackability, especially for researchers that are not familiar with C++.

그러나 검색 알고리즘을 딥 뉴럴 네트워크와 결합하여 사용하는 것은 일반적으로 빠른 컴파일 언어로 작성된 효율적인 구현을 필요로 하며, 이는 사용성과 해킹 가능성을 희생시킬 수 있습니다. 특히 C++에 익숙하지 않은 연구자들에게는 더욱 그렇습니다.

In Reinforcement Learning the agent must learn to interact with the environment in order to maximize a scalar reward signal.

강화 학습에서 에이전트는 스칼라 보상 신호를 최대화하기 위해 환경과 상호작용하는 방법을 배워야 합니다.

On each step the agent must select an action and receives in exchange an observation and a reward.

각 단계에서 에이전트는 행동을 선택해야 하며, 그 대가로 관측값과 보상을 받습니다.

Alternatively, search allows to select actions by constructing on the fly, in each state, a policy or a value function local to the current state, by searching using a learned model of the environment.

대안적으로, search는 학습된 환경 모델을 사용하여 검색함으로써, 각 상태에서 현재 상태에 로컬인 정책이나 가치 함수를 즉석에서 구성함으로써 행동을 선택할 수 있게 해줍니다.

Typically priors are needed to guide which nodes in the search tree to expand (to reduce the breadth of the tree that we construct), and value functions are used to estimate the value of incomplete paths in the tree that don't reach an episode termination (to reduce the depth of the search tree).

일반적으로 사전 지식은 검색 트리에서 어떤 노드를 확장할지 안내하는 데 필요합니다(우리가 구성하는 트리의 폭을 줄이기 위해), 그리고 가치 함수는 에피소드 종료에 도달하지 않는 트리의 불완전한 경로의 가치를 추정하는 데 사용됩니다(검색 트리의 깊이를 줄이기 위해).

The `RootFnOutput` contains the `prior_logits` from a policy network, the estimated `value` of the root state, and any `embedding` suitable to represent the root state for the environment model.

`RootFnOutput`은 정책 네트워크에서의 `prior_logits`, 루트 상태의 추정된 `value`, 그리고 환경 모델에 대한 루트 상태를 나타내기에 적합한 모든 `embedding`을 포함합니다.

A few fix-ups needed.

몇 가지 수정이 필요합니다.

We've said most of what we'll say about this topic now.

우리는 지금 이 주제에 관해 말할 내용의 대부분을 말했습니다.

The formula is good for error estimates: the only division is by the determinant, so if your determinant is tiny, your error bars are large.

오류 추정에 좋은 공식입니다: 분모는 행렬식뿐이므로, 행렬식이 매우 작으면 오차 범위도 큽니다.

@@@

Cofactor expansion is recursive, but you don't have to use cofactor expansion to compute the determinants of the minors! Or you can do row operations and then a cofactor expansion.

여인수 전개는 재귀적이지만, 소행렬식의 행렬식을 구하기 위해 꼭 여인수 전개를 사용할 필요는 없습니다! 또는 행 연산을 한 다음에 여인수 전개를 할 수도 있습니다.

If all scientific papers whose results are in doubt because of bad `rand()`s were to disappear from library shelves, there would be a gap on each shelf about as big as your fist.

만약 결과가 좋지 않은 `rand()` 때문에 의심받는 모든 과학 논문들이 도서관의 서가에서 사라진다면, 각 서가마다 주먹만한 크기의 공간이 생길 것이다.

You’re used to *stateful* pseudorandom number generators (PRNGs) from numpy and other libraries, which helpfully hide a lot of details under the hood to give you a ready fountain of pseudorandomness:

numpy와 다른 라이브러리들에서 사용하는 상태 유지형 의사난수 생성기(PRNGs)에 익숙하며, 이들은 많은 세부 사항들을 숨겨서 사용자에게 준비된 의사난수의 원천을 제공한다.

Underneath the hood, numpy uses the Mersenne Twister PRNG to power its pseudorandom functions.

numpy는 내부적으로 메르센 트위스터(Mersenne Twister) PRNG를 사용하여 그것의 의사난수 함수들을 구동한다.

The PRNG has a period of 2^19937−1 and at any point can be described by **624 32bit unsigned ints** and a **position** indicating how much of this “entropy” has been used up.

PRNG는 2^19937−1의 주기를 가지고 있으며, 어느 시점에서든 624개의 32비트 unsigned int와, 이 '엔트로피'가 얼마나 사용되었는지를 나타내는 위치로 설명될 수 있다.

The problem with magic PRNG state is that it’s hard to reason about how it’s being used and updated across different threads, processes, and devices, and it’s very easy to screw up when the details of entropy production and consumption are hidden from the end user.

매직 PRNG 상태의 문제점은 다른 스레드, 프로세스, 장치들 간에 어떻게 사용되고 업데이트되는지 이해하기 어렵고, 엔트로피 생성 및 소비의 세부사항이 최종 사용자로부터 숨겨져 있을 때 실수하기 매우 쉽다는 것이다.

That is, its design allows us to **fork** the PRNG state into new PRNGs for use with parallel stochastic generation.

즉, 그것의 설계는 PRNG 상태를 **fork**하여 새로운 PRNG들로 만들고, 이를 병렬 확률적 생성에 사용할 수 있게 해준다.

Reusing the same state will cause **sadness** and **monotony**, depriving the end user of **lifegiving chaos**:

동일한 상태를 재사용하면 슬픔과 단조로움을 유발하여 최종 사용자에게 생동감 넘치는 혼란을 줄 수 있습니다:

In this section we focus on pseudo random number generation (PRNG); that is, the process of algorithmically generating sequences of numbers whose properties approximate the properties of sequences of random numbers sampled from an appropriate distribution.

이 섹션에서는 의사 난수 생성(PRNG)에 초점을 맞춥니다; 즉, 적절한 분포에서 샘플링된 난수 시퀀스의 속성을 근사하는 속성을 가진 숫자 시퀀스를 알고리즘적으로 생성하는 과정입니다.

Generally, JAX strives to be compatible with NumPy, but pseudo random number generation is a notable exception.

일반적으로 JAX는 NumPy와의 호환성을 추구하지만, 의사 난수 생성은 주목할 만한 예외입니다.

To better understand the difference between the approaches taken by JAX and NumPy when it comes to random number generation we will discuss both approaches in this section.

JAX와 NumPy가 난수 생성에 있어서 취하는 접근 방식의 차이를 더 잘 이해하기 위해, 이 섹션에서는 두 접근 방식에 대해 논의할 것입니다.

It doesn’t matter which part of the output of `split(key)` we call `key`, and which we call `subkey`.

`split(key)`의 출력 중 어느 부분을 `key`로 부르고, 어느 부분을 `subkey`로 부르는지는 중요하지 않다.

We want a PRNG design that is **expressive** in that it is convenient to use and it doesn’t constrain the user’s ability to write numerical programs with exactly the behavior that they want,

우리는 사용하기 편리하며 사용자가 원하는 정확한 동작을 가진 수치 프로그램을 작성하는 능력을 제한하지 않는, 표현력이 있는 PRNG 설계를 원한다,

We want a PRNG design that has semantics that are **invariant to `@jit` compilation boundaries and device backends,**

우리는 @jit 컴파일 경계와 디바이스 백엔드에 불변하는 의미론을 가진 PRNG 설계를 원한다,

We want a PRNG design that is **parallelizable** in that it doesn’t add sequencing constraints between random function calls that otherwise would have no data dependence,

우리는 랜덤 함수 호출 간에 데이터 의존성이 없는 시퀀싱 제약을 추가하지 않는다는 점에서 병렬화 가능한 PRNG 설계를 원합니다,

Even if we didn’t require reproducibility and thus allowed any evaluation order, parallelization across calls (#5) would still be made difficult by the need to update shared state.

재현성을 요구하지 않고 어떤 평가 순서도 허용한다 해도, 공유 상태를 업데이트해야 하는 필요성 때문에 호출 간 병렬화(#5)는 여전히 어려울 것이다.

Moreover, because the same PRNG state would need to be accessed and maintained in both Python and any compiled code, this model would likely lead to engineering challenges to achieve compilation invariance (#3) and scaling to multiple replicas (#6).

또한, 동일한 PRNG 상태가 파이썬과 컴파일된 코드 양쪽에서 접근 및 유지되어야 하기 때문에, 이 모델은 컴파일 불변성(#3)을 달성하고 여러 복제본으로 확장하는 데(#6) 엔지니어링 측면의 도전이 될 가능성이 높다.

