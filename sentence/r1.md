We obtain both state-of-the-art results and anecdotal evidence demonstrating the importance of the value distribution in approximate reinforcement learning.

우리는 근사 강화 학습에서 가치 분포의 중요성을 입증하는 최신 결과와 일화적 증거를 모두 얻었습니다.

Finally, we combine theoretical and empirical evidence to highlight the ways in which the value distribution impacts learning in the approximate setting.

마지막으로, 우리는 이론적 및 경험적 증거를 결합하여 근사 설정에서 가치 분포가 학습에 미치는 영향을 강조합니다.

One of the major tenets of reinforcement learning states that, when not otherwise constrained in its behaviour, an agent should aim to maximize its expected utility Q, or Value (Sutton & Barto, 1998).

강화 학습의 주요 원칙 중 하나는, 행동에 다른 제약이 없는 경우, 에이전트는 기대 유틸리티 Q 또는 Value를 최대화하는 것을 목표로 해야 한다고 명시합니다 (Sutton & Barto, 1998).

Bellman’s equation succinctly describes this value in terms of the expected reward and expected outcome of the random transition $(x, a) → (X, A)$.

벨만 방정식은 기대 보상과 무작위 전환 $(x, a) → (X', A')$의 예상 결과 측면에서 이 Value를 간결하게 설명합니다.

In this paper, we aim to go beyond the notion of value and argue in favour of a distributional perspective on reinforcement learning.

이 논문에서는 Value 개념을 넘어서 강화 학습에 대한 분포적 관점을 지지하는 논의를 하고자 합니다.

This random return is also described by a recursive equation, but one of a distributional nature:

이 무작위 반환도 재귀 방정식에 의해 설명되지만, 그것은 분포적 성격을 가진 방정식입니다.

By analogy with the well-known case, we call this quantity the value distribution.

잘 알려진 경우와 비슷하게, 우리는 이 양을 Value distribution이라고 부릅니다.

in reinforcement learning it has thus far been subordinated to specific purposes.

강화 학습에서는 지금까지 특정 목적에 종속되어 왔습니다.

Specifically, although the optimality operator is a contraction in expected value (matching the usual optimality result), it is not a contraction in any metric over distributions.

구체적으로, 최적성 연산자가 예상 가치에서 수축(통상적인 최적성 결과와 일치)하는 것은 사실이지만, 분포에 대한 어떤 척도에서도 수축이 아닙니다.

These results provide evidence in favour of learning algorithms that model the effects of nonstationary policies.

이 결과들은 비정상적(nonstationary) 정책의 영향을 모델링하는 학습 알고리즘을 지지하는 증거를 제공합니다.

As a whole, we argue that this approach makes approximate reinforcement learning significantly better behaved.

전체적으로, 우리는 이 접근 방식이 근사 강화 학습을 훨씬 더 잘 행동하게 만든다고 주장합니다.

By modelling the value distribution within a DQN agent (Mnih et al., 2015), we obtain considerably increased performance across the gamut of benchmark Atari 2600 games, and in fact achieve state-of-the-art performance on a number of games.

DQN 에이전트(Mnih et al., 2015) 내에서 Value distribution을 모델링함으로써, 벤치마크 Atari 2600 게임 전반에 걸쳐 상당히 향상된 성능을 얻었으며, 실제로 여러 게임에서 최신 성능을 달성했습니다.

The main distinction, of course, is that in our setting there are no given targets.

물론, 우리 설정의 주요 차이점은 주어진 목표가 없다는 것입니다.

Our first aim is to gain an understanding of the theoretical behaviour of the distributional analogues of the Bellman operators, in particular in the less well-understood control setting.

우리의 첫 번째 목표는 벨만 연산자의 분포적 유사물, 특히 덜 이해된 제어 설정에서의 이론적 행동에 대한 이해를 얻는 것입니다.

We will find it convenient to conflate the random variables under consideration with their versions under the $\text{inf}$, writing $d_p(U, V)= \underset{U, V}{\text{inf}}\| U - V\|_p$ whenever it is unambiguous:

고려 중인 무작위 변수를 $\text{inf}$ 아래에 해당 버전과 결합하고 모호하지 않을 때마다 $d_p(U, V)= \underset{U, V}{\text{inf}}\| U - V\|_p$을 작성하는 것이 편리할 것입니다:

we believe the greater legibility justifies the technical inaccuracy.

우리는 더 큰 가독성이 기술적 부정확성을 정당화한다고 믿습니다.

We will need the following additional property, which makes no independence assumptions on its variables.

우리는 변수에 대한 독립성 가정을 하지 않는 다음과 같은 추가적인 속성이 필요합니다.

@@@

While Tπ bears a surface resemblance to the usual Bellman operator (2), it is fundamentally different.

Tπ는 표면적으로는 일반적인 벨만 연산자(2)와 유사해 보이지만, 근본적으로 다릅니다.

In particular, three sources of randomness define the compound distribution $\mathcal{T}^{π}Z$:

특히, 세 가지 무작위성 소스가 복합 분포 $\mathcal{T}^{π}Z$를 정의합니다:

We now set out to understand the distributional operators of the control setting – where we seek a policy $π$ that maximizes value –and the corresponding notion of an optimal value distribution.

이제 우리는 가치를 극대화하는 정책 $π$를 추구하는 제어 설정의 분포 연산자와 최적 가치 분포에 해당하는 개념을 이해하려고 합니다.

As with the optimal value function, this notion is intimately tied to that of an optimal policy.

최적 가치 함수와 마찬가지로, 이 개념은 최적 정책과 밀접하게 연결되어 있습니다.

In this section we show that the distributional analogue of the Bellman optimality operator converges, in a weak sense, to the set of optimal value distributions.

이 섹션에서는 벨만 최적성 연산자의 분포적 유사체가 약한 의미에서 최적 가치 분포 집합으로 수렴한다는 것을 보여줍니다.

However, this operator is not a contraction in any metric between distributions, and is in general much more temperamental than the policy evaluation operators.

그러나 이 연산자는 분포 간의 어떤 척도에서도 수축이 아니며, 일반적으로 정책 평가 연산자들보다 훨씬 더 변덕스럽습니다.

We believe the convergence issues we outline here are a symptom of the inherent instability of greedy updates, as highlighted by e.g. Tsitsiklis (2002) and most recently Harutyunyan et al. (2016).

여기서 개요를 제시하는 수렴 문제들은 Tsitsiklis (2002)와 가장 최근에 Harutyunyan et al. (2016)이 강조한 바와 같이, 탐욕스러운 업데이트의 내재적 불안정성의 증상이라고 믿습니다.

Although this policy is implicit in (6), we cannot ignore it in the distributional setting.

이 정책이 (6)에서는 암시되어 있지만, 분포적 설정에서는 무시할 수 없습니다.

By inspecting Lemma 4.

Lemma 4를 검토함으로써.

In fact, the best we can hope for is pointwise convergence, not even to the set $\mathcal{Z}^{∗}$ but to the larger set of nonstationary optimal value distributions.

사실, 우리가 바랄 수 있는 최선은 $\mathcal{Z}^{∗}$ 집합이 아니라 더 큰 비정상적(nonstationary) 최적 가치 분포 집합에 대한 점별 수렴입니다.

Statistical learning refers to a set of tools for making sense of complex datasets.

통계적 학습은 복잡한 데이터셋을 이해하기 위한 일련의 도구들을 의미합니다.

In recent years, we have seen a staggering increase in the scale and scope of data collection across virtually all areas of science and industry.

최근 몇 년 동안, 과학과 산업의 거의 모든 분야에서 데이터 수집의 규모와 범위가 엄청나게 증가했다는 것을 목격하였습니다.

Since it was published in 2013, ISLR has become a mainstay of undergraduate and graduate classrooms worldwide, as well as an important reference book for data scientists.

2013년에 출판된 이후, ISLR은 전 세계 대학교의 학부 및 대학원 교실에서 중요한 교재로 자리잡았으며, 데이터 과학자들에게 중요한 참고서로도 사용되고 있습니다.

The intention behind ISLP (and ISLR) is to concentrate more on the applications of the methods and less on the mathematical details, so it is appropriate for advanced undergraduates or master’s students in statistics or related quantitative fields, or for individuals in other disciplines who wish to use statistical learning tools to analyze their data.

ISLP(와 ISLR)의 목적은 방법론의 적용에 더 초점을 맞추고 수학적 세부 사항에는 덜 집중하는 것이므로, 통계학이나 관련 정량적 분야의 고급 학부생이나 석사 과정 학생들, 또는 자신들의 데이터를 분석하기 위해 통계적 학습 도구를 사용하고자 하는 다른 분야의 개인에게 적합합니다.

It has been an honor and a privilege for us to see the considerable impact that ISLR has had on the way in which statistical learning is practiced, both in and out of the academic setting.

ISLR이 학계 안팎에서 통계적 학습이 실행되는 방식에 미친 상당한 영향을 목격하는 것은 우리에게 영광이자 특권이었습니다.

Statistical learning refers to a vast set of tools for understanding data.

통계적 학습은 데이터를 이해하기 위한 광범위한 도구들을 의미합니다.

However, it is also clear from Figure 1.1 that there is a significant amount of variability associated with this average value, and so age alone is unlikely to provide an accurate prediction of a particular man’s wage.

그러나 그림 1.1에서 분명히 보이듯이, 이 평균 값에는 상당한 변동성이 관련되어 있으며, 따라서 나이만으로는 특정 남성의 임금을 정확히 예측하기 어려울 것입니다.

Wages increase by approximately $10,000, in a roughly linear (or straight-line) fashion, between 2003 and 2009, though this rise is very slight relative to the variability in the data.

2003년부터 2009년 사이에 임금은 대략 $10,000 증가하며, 이는 대략적으로 선형적(또는 직선적)인 방식으로 이루어집니다. 그러나 이 증가는 데이터의 변동성에 비해 매우 미미합니다.

Boxplots of the previous day’s percentage change in the S&P index for the days for which the market increased or decreased, obtained from the Smarket data.

Smarket 데이터에서 얻은, 시장이 상승하거나 하락한 날들에 대한 S&P 지수의 전날 퍼센트 변화에 대한 박스플롯입니다.

A model that could accurately predict the direction in which the market will move would be very useful!

시장이 움직일 방향을 정확하게 예측할 수 있는 모델은 매우 유용할 것입니다!

The left-hand panel of Figure 1.2 displays two boxplots of the previous day’s percentage changes in the stock index: one for the 648 days for which the market increased on the subsequent day, and one for the 602 days for which the market decreased.

그림 1.2의 왼쪽 패널은 주식 지수의 전날 퍼센트 변화에 대한 두 개의 박스플롯을 보여줍니다: 하나는 시장이 다음 날 상승한 648일에 대한 것이고, 다른 하나는 시장이 하락한 602일에 대한 것입니다.

Of course, this lack of pattern is to be expected: in the presence of strong correlations between successive days’ returns, one could adopt a simple trading strategy to generate profits from the market.

물론, 이러한 패턴의 부재는 예상되는 바입니다: 연속적인 날들의 수익률 사이에 강한 상관관계가 있을 경우, 시장에서 수익을 창출하기 위해 간단한 거래 전략을 채택할 수 있습니다.

Interestingly, there are hints of some weak trends in the data that suggest that, at least for this 5-year period, it is possible to correctly predict the direction of movement in the market approximately 60% of the time (Figure 1.3).

흥미롭게도, 데이터에는 약한 추세의 단서가 있어, 적어도 이 5년 기간 동안 시장의 움직임 방향을 약 60%의 정확도로 예측할 수 있다는 것을 시사합니다 (그림 1.3).

For example, in a marketing setting, we might have demographic information for a number of current or potential customers.

예를 들어, 마케팅 상황에서, 우리는 현재 또는 잠재 고객들에 대한 인구통계적 정보를 가지고 있을 수 있습니다.

We fit a quadratic discriminant analysis model to the subset of the Smarket data corresponding to the 2001–2004 time period, and predicted the probability of a stock market decrease using the 2005 data.

Quadratic discriminant analysis 모델을 2001년부터 2004년까지의 기간에 해당하는 Smarket 데이터의 부분집합에 적용하고, 2005년 데이터를 사용하여 주식 시장 하락의 확률을 예측했습니다.

On average, the predicted probability of decrease is higher for the days in which the market does decrease.

평균적으로, 시장이 하락하는 날에는 하락할 확률이 더 높게 예측됩니다.

We devote Chapter 12 to a discussion of statistical learning methods for problems in which no natural output variable is available.

우리는 자연스러운 출력 변수가 없는 문제에 대한 통계적 학습 방법에 대한 논의를 12장에 할애합니다.

There is clear evidence that cell lines with the same cancer type tend to be located near each other in this two-dimensional representation.

이러한 이차원 표현에서 같은 암 유형을 가진 세포주들이 서로 가까이 위치하는 경향이 있다는 명확한 증거가 있습니다.

In addition, even though the cancer information was not used to produce the left-hand panel, the clustering obtained does bear some resemblance to some of the actual cancer types observed in the right-hand panel.

또한, 왼쪽 패널을 생성하는 데 암 정보가 사용되지 않았음에도 불구하고, 얻어진 군집은 실제로 오른쪽 패널에서 관찰된 일부 암 유형과 어느 정도 유사성을 보입니다.

This provides some independent verification of the accuracy of our clustering analysis.

이것은 우리의 군집 분석의 정확성에 대한 독립적인 검증을 제공합니다.

@@@

At the beginning of the nineteenth century, the method of least squares was developed, implementing the earliest form of what is now known as linear regression.

19세기 초, least squares라는 방법이 개발되었으며, 이는 지금으로서는 linear regression으로 알려진 가장 초기의 형태를 구현했습니다.

In the 1940s, various authors put forth an alternative approach, logistic regression.

1940년대에 여러 저자들이 대안적인 접근 방식인 logistic regression을 제시했습니다.

However, they were almost exclusively linear methods because fitting non-linear relationships was computationally difficult at the time.

그러나 당시에는 non-linear 관계를 맞추는 것이 계산적으로 어려웠기 때문에 거의 대부분 linear 방법들이었습니다.

This has the potential to continue the transformation of the field from a set of techniques used and developed by statisticians and computer scientists to an essential toolkit for a much broader community.

이것은 통계학자들과 컴퓨터 과학자들이 사용하고 개발한 일련의 기술에서 훨씬 더 넓은 커뮤니티에 필수적인 도구 모음으로 분야를 계속 변화시킬 잠재력이 있습니다.

Its success derives from its comprehensive and detailed treatment of many important topics in statistical learning, as well as the fact that (relative to many upper-level statistics textbooks) it is accessible to a wide audience.

이 책의 성공은 통계 학습에서 중요한 많은 주제들을 종합적이고 상세하게 다루었다는 점과, 많은 상급 수준의 통계 교재들과 비교할 때 폭넓은 독자층에게 접근하기 쉽다는 사실에서 비롯됩니다.

The most obvious growth has involved the development of new and improved statistical learning approaches aimed at answering a range of scientific questions across a number of fields.

가장 명백한 발전은 다양한 분야에서 과학적 질문에 답하기 위해 새롭고 개선된 통계 학습 방법론의 개발에 관련되어 있습니다.

In the 1990s, increases in computational power generated a surge of interest in the field from non-statisticians who were eager to use cutting-edge statistical tools to analyze their data.

1990년대에는 컴퓨터 연산력의 증가가 비통계학자들 사이에서 관심을 불러일으켰고, 이들은 최신 통계 도구를 사용하여 데이터를 분석하는 데 열심이었습니다.

Unfortunately, the highly technical nature of these approaches meant that the user community remained primarily restricted to experts in statistics, computer science, and related fields with the training (and time) to understand and implement them.

유감스럽게도 이러한 접근법의 고도로 기술적인 성격 때문에 사용자 커뮤니티는 주로 통계학, 컴퓨터 과학, 관련 분야의 전문가들로 제한되었으며, 이들은 이를 이해하고 구현하기 위한 교육(및 시간)을 갖추고 있었습니다.

In recent years, new and improved software packages have significantly eased the implementation burden for many statistical learning methods.

최근 몇 년 동안 새롭고 개선된 소프트웨어 패키지들이 많은 통계 학습 방법들의 구현 부담을 크게 줄여주었습니다.

ISL is not intended to replace ESL, which is a far more comprehensive text both in terms of the number of approaches considered and the depth to which they are explored.

ISL은 ESL을 대체하기 위한 것이 아니며, ESL은 고려된 접근 방법의 수와 그들이 탐구된 깊이 면에서 훨씬 더 포괄적인 텍스트입니다.

In teaching these topics over the years, we have discovered that they are of interest to master’s and PhD students in fields as disparate as business administration, biology, and computer science, as well as to quantitatively-oriented upper-division undergraduates.

여러 해에 걸쳐 이러한 주제들을 가르치면서, 우리는 이들이 경영학, 생물학, 컴퓨터 과학과 같이 다양한 분야의 석사 및 박사 과정 학생들과, 정량적으로 지향하는 상급 학부생들에게도 관심을 끌고 있다는 것을 발견했습니다.

We believe that these students do not need a deep understanding of these aspects in order to become informed users of the various methodologies, and in order to contribute to their chosen fields through the use of statistical learning tools.

우리는 이러한 학생들이 다양한 방법론의 정보에 밝은 사용자가 되고, 통계 학습 도구를 사용하여 자신이 선택한 분야에 기여하기 위해 이러한 측면들에 대한 깊은 이해가 필요하지 않다고 믿습니다.

ISL is based on the following four premises.

ISL은 다음의 네 가지 전제에 기반을 두고 있습니다.

Many statistical learning methods are relevant and useful in a wide range of academic and non-academic disciplines, beyond just the statistical sciences.

많은 통계 학습 방법들은 통계 과학뿐만 아니라 광범위한 학문적 및 비학문적 분야에서도 관련성이 있고 유용합니다.

We believe that many contemporary statistical learning procedures should, and will, become as widely available and used as is currently the case for classical methods such as linear regression.

우리는 많은 현대 통계 학습 절차들이 선형 회귀와 같은 고전적 방법들처럼 현재와 같이 널리 이용 가능하고 사용될 것이라고 믿습니다.

As a result, rather than attempting to consider every possible approach (an impossible task), we have concentrated on presenting the methods that we believe are most widely applicable.

그 결과, 모든 가능한 접근 방법을 고려하는 것(불가능한 일)보다는, 우리가 가장 널리 적용 가능하다고 믿는 방법들을 제시하는 데 집중하였습니다.

This is a good example of an instance where having a conceptual viewpoint saves you a lot of work.

이는 개념적 관점이 있으면 많은 작업을 절약할 수 있는 좋은 예입니다.

In fact, AB may be defined when BA is not.

실제로 AB는 BA가 정의되지 않은 경우에 정의될 수 있습니다.

You have to be careful when multiplying matrices together, because things like commutativity and cancellation fail.

행렬을 곱할 때 주의해야 하는데, 교환법칙과 소거법칙과 같은 것들이 실패할 수 있습니다.

We begin by characterizing what we mean by an optimal value distribution.

최적의 가치 분포가 무엇을 의미하는지 특성화하는 것부터 시작합니다.

Without understanding all of the cogs inside the box, or the interaction between those cogs, it is impossible to select the best box.

상자 안의 모든 톱니바퀴들이나 그 톱니바퀴들 간의 상호작용을 이해하지 않고서는 최적의 상자를 선택하는 것이 불가능합니다.

We presume that the reader is interested in applying statistical learning methods to real-world problems.

우리는 독자가 실제 세계의 문제에 통계 학습 방법을 적용하는 데 관심이 있다고 가정합니다.

Many of the less computationally-oriented students who were initially intimidated by the labs got the hang of things over the course of the quarter or semester.

계산에 중점을 두지 않은 많은 학생들이 처음에는 lab에 겁을 먹었지만, 학기나 학기 동안 점차 일에 익숙해졌습니다.

However, the labs in ISL are self-contained, and can be skipped if the reader wishes to use a different software package or does not wish to apply the methods discussed to real-world problems.

그러나 ISL의 lab은 독립적으로 구성되어 있어, 독자가 다른 소프트웨어 패키지를 사용하길 원하거나 실제 세계의 문제에 논의된 방법들을 적용하고 싶지 않은 경우 건너뛸 수 있습니다.

This group includes scientists, engineers, data analysts, data scientists, and quants, but also less technical individuals with degrees in non-quantitative fields such as the social sciences or business.

이 그룹에는 과학자, 엔지니어, 데이터 분석가, 데이터 과학자, 퀀트뿐만 아니라 사회 과학이나 비즈니스와 같은 비정량적 분야의 학위를 가진 덜 기술적인 개인들도 포함됩니다.

In the rare cases in which these two uses for lower case normal font lead to ambiguity, we will clarify which use is intended.

이러한 두 가지 용도가 소문자 일반 폰트 사용에서 드물게 모호함을 초래하는 경우에는, 우리는 어떤 용도가 의도된 것인지 명확히 할 것입니다.

However, in a few instances it becomes too cumbersome to avoid it entirely.

그러나 몇몇 경우에는 완전히 피하는 것이 너무 번거로워집니다.

We then show how these methods can be used to fit non-linear additive models for which there is more than one input.

그런 다음 이러한 방법들을 하나 이상의 입력이 있는 비선형 가산 모델에 적용하는 방법을 보여줍니다.

These can be easily skipped by readers who do not wish to delve as deeply into the material, or who lack the mathematical background.

이들은 자료에 깊이 파고들고 싶지 않거나 수학적 배경이 부족한 독자들에 의해 쉽게 건너뛰어질 수 있습니다.

How on earth do you remember this?

이걸 어떻게 기억하나요?

This is a crucial component of the change-of-variables formula in multivariable calculus.

이것은 다변수 미적분에서 변수 변환 공식의 중요한 구성 요소입니다.

This is even true for curvy shapes, in the following sense.

이것은 다음과 같은 의미에서 곡선 모양에도 마찬가지로 적용됩니다.

Let S be the unit disk in $R^2$,

S를 $R^2$의 단위 원으로 두고,

JAX is laser-focused on program transformations and accelerator-backed NumPy, so we don’t include data loading or munging in the JAX library.

JAX는 프로그램 변환과 가속기 기반의 NumPy에 집중하고 있어, JAX 라이브러리에 데이터 로딩이나 가공을 포함하지 않습니다.

In other words, our goal is to develop an accurate model that can be used to predict sales on the basis of the three media budgets.

다시 말해, 우리의 목표는 세 가지 미디어 예산을 기반으로 판매를 예측할 수 있는 정확한 모델을 개발하는 것입니다.

More generally, suppose that we observe a quantitative response $Y$ and $p$ different predictors, $X_1, X_2,...,X_p$.

보다 일반적으로, 우리가 정량적인 반응 $Y$와 $p$개의 다른 예측 변수들, $X_1, X_2,...,X_p$를 관찰한다고 가정해 봅시다.

The plot displays sales, in thousands of units, as a function of `TV`, `radio`, and `newspaper` budgets, in thousands of dollars, for 200 different markets.

이 그래프는 200개의 다른 시장에 대해, 수천 달러 단위의 `TV`, `radio`, `newspaper` 예산을 function으로 하는 수천 단위의 판매량을 보여줍니다.

In this setting, $\hat{f}$ is often treated as a *black box*, in the sense that one is not typically concerned with the exact form of $\hat{f}$, provided that it yields accurate predictions for $Y$.

이 상황에서, $\hat{f}$는 종종 *black box* 로 취급되며, 그것이 $Y$에 대한 정확한 예측을 제공한다면 $\hat{f}$의 정확한 형태에 대해 일반적으로 걱정하지 않는다는 의미에서 그렇습니다.

It is often the case that only a small fraction of the available predictors are substantially associated with $Y$. Identifying the few important predictors among a large set of possible variables can be extremely useful, depending on the application.

주로 사용 가능한 예측 변수들 중 극히 일부만이 $Y$와 실질적으로 연관되어 있습니다. 많은 가능한 변수들 중 몇 가지 중요한 예측 변수를 식별하는 것은 응용에 따라 매우 유용할 수 있습니다.

For instance, to what extent is the product’s price associated with sales?

예를 들어, 제품의 가격이 판매와 어느 정도 연관되어 있나요?

For example, in a real estate setting, one may seek to relate values of homes to inputs such as crime rate, zoning, distance from a river, air quality, schools, income level of community, size of houses, and so forth.

예를 들어 부동산 상황에서, 주택 가치를 범죄율, 구역 지정, 강으로부터의 거리, 공기 질, 학교, 지역사회의 소득 수준, 주택 크기 등과 같은 입력 값과 연관시키려 할 수 있습니다.

This enables planning to be interrupted or redirected at any time with little wasted computation, which appears to be a key requirement for efficiently intermixing planning with acting and with learning of the model.

이렇게 하면 낭비되는 계산량이 거의 없이 언제든 계획을 수행하는 중간에 끼어들거나 진행 방향을 바꿀 수 있다. 이것은 계획을 행동 및 모델에 대한 학습과 효과적으로 혼합하기 위한 핵심 요구조건인 것처럼 보인다.

Because planning proceeds incrementally, it is trivial to intermix planning and acting.

계획이 점증적으로 진행되기 때문에, 계획과 행동을 혼합하는 것은 식은 죽 먹기다.

This tends to happen when the model is optimistic in the sense of predicting greater reward or better state transitions than are actually possible.

실제로 가능한 것보다 더 큰 보상 또는 더 좋은 상태 전이를 예측한다는 측면에서 모델이 긍정적일 경우 이러한 상황이 발생하는 경향이 있다.

This encourages the agent to keep testing all accessible state transitions and even to find long sequences of actions in order to carry out such tests.

이것은 학습자로 하여금 접근 가능한 모든 상태 전이에 대해 계속 테스트하고, 심지어는 그러한 테스트를 수행하기 위해 행동의 긴 나열을 찾도록 장려한다.

As planning progresses, the region of useful updates grows, but planning is still far less efficient than it would be if focused where it would do the most good.

계획이 진행됨에 따라 유용한 갱신의 영역은 커지지만, 계획 자체는 계획이 가장 잘 수행되는 곳에 초점을 맞추었을 때보다 여전히 훨씬 더 비효율적이다.

In the much larger problems that are our real objective, the number of states is so large that an unfocused search would be extremely inefficient.

이 책의 진정한 목표인 훨씬 더 규모가 큰 문제에서는 상태의 개수가 상당히 많아서 초점 없는 탐색이 극도로 비효율적일 것이다.

In this way one can work backward from arbitrary states that have changed in value, either performing useful updates or terminating the propagation. This general idea might be termed *backward focusing* of *planning computations*.

이러한 방식으로 가치가 변한 임의의 상태로부터 역방향으로 진행할 수 있다. 이 과정에서 유용한 갱신을 할 수도 있고 진행을 멈출 수도 있다. 이러한 일반적인 개념을 이름하여 계획 계산(planning computation)의 역행 초점(backward focusing)이라고 부를 수도 있다.

Sample updates can win because they break the overall backing-up computation into smaller pieces—those corresponding to individual transitions—which then enables it to be focused more narrowly on the pieces that will have the largest impact. This idea was taken to what may be its logical limit in the “small backups” introduced by van Seijen and Sutton (2013).

표본 갱신이 전체 보강 계산을 개별 전이 각각에 해당하는 더 작은 조각으로 나눔으로써 가장 큰 영향력이 있는 조각들에 더 좁게 초점을 맞출 수 있도록 하기 때문에 표본 갱신의 성능이 더 좋을 수 있다. 이 개념은 반 세이젠과 서튼(2013)이 소개한 '작은 보강'에서 그 개념의 논리적 한계일 수도 있는 것에 적용되었다.

For example, another would be to focus on states according to how easily they can be reached from the states that are visited frequently under the current policy, which might be called *forward focusing*.

예를 들어, 또 다른 전략은 현재 정책하에서 자주 마주치는 상태로부터 얼마나 쉽게 그 상태에 도달할 수 있는지에 따라 상태에 초점을 두는 것이다. 이러한 전략을 순행(forward focusing)이라고 부를 수도 있다.

You can notice the first difference if you check the type of `x`. It is a variable of type `Array`, which is the way JAX represents arrays.

x의 타입을 확인하면 첫 번째 차이점을 알 수 있습니다. `x`는 `Array` 타입의 변수로, 이는 JAX가 배열을 나타내는 방식입니다.

The returned array is therefore not necessarily ‘filled in’ as soon as the function returns. Thus, if we don’t require the result immediately, the computation won’t block Python execution.

따라서 반환된 배열은 함수가 반환되자마자 반드시 '채워진' 상태는 아닙니다. 그러므로 결과가 즉시 필요하지 않다면, 계산이 Python 실행을 차단하지 않을 것입니다.

In addition to wanting to log the value, we often want to report some intermediate results obtained in computing the loss function.

값을 기록하고 싶은 것 외에도, 우리는 종종 손실 함수를 계산하는 과정에서 얻은 중간 결과를 보고하고 싶어 합니다.

The most important difference, and in some sense the root of all the rest, is that JAX is designed to be functional, as in functional programming.

가장 중요한 차이점이자, 어떤 의미에서 모든 다른 차이의 근원은 JAX가 함수형 프로그래밍과 같이 함수형으로 설계되었다는 것입니다.

The reason behind this is that the kinds of program transformations that JAX enables are much more feasible in functional-style programs.

이것의 이유는 JAX가 가능하게 하는 프로그램 변환의 종류가 함수형 스타일의 프로그램에서 훨씬 더 실현 가능하기 때문입니다.

However, as we will explain in the next guide, JAX computations are often compiled before being run using another program transformation, `jax.jit`.

하지만, 다음 가이드에서 설명하겠지만, JAX 계산은 종종 실행되기 전에 다른 프로그램 변환인 `jax.jit`를 사용하여 컴파일됩니다.

If we don’t use the old array after modifying it ‘in place’ using indexed update operators, the compiler can recognise that it can in fact compile to an in-place modify, resulting in efficient code in the end.

인덱스 업데이트 연산자를 사용하여 '현장에서' 수정한 후 이전 배열을 사용하지 않으면, 컴파일러는 실제로 현장에서의 수정으로 컴파일할 수 있다는 것을 인식하여, 결국 효율적인 코드를 생성할 수 있습니다.

We will explain other places where the JAX idiosyncrasies become relevant as they come up.

JAX의 특이한 점이 등장하는 대로 관련성이 있는 다른 곳에 대해 설명해 드리겠습니다.

The main difference between this example and real training loops is the simplicity of our model: that allows us to use a single array to house all our parameters.

이 예시와 실제 훈련 루프 사이의 주된 차이점은 우리 모델의 단순성입니다: 이것은 모든 매개변수를 하나의 배열에 담을 수 있게 해줍니다.

The (algebraic) multiplicity of an eigenvalue λ is its multiplicity as a root of the characteristic polynomial.

고유값 λ의 (대수적) 중복도는 특성 다항식의 근으로서의 중복도입니다.

It's easy to factor quadratic polynomials.

이차 다항식을 인수분해하는 것은 쉽습니다.

First we talked about the geometry of eigenvalues and eigenvectors.

먼저 고유값과 고유벡터의 기하학에 대해 이야기했습니다.

Instead they seek an estimate of $f$ that gets as close to the data points as possible without being too rough or wiggly.

대신에, 너무 거칠거나 흔들리지 않으면서 가능한 한 데이터 포인트에 가까운 $f$의 추정치를 찾으려 합니다.

This approach does not impose any pre-specified model on $f$.

이 접근법은 $f$에 사전에 지정된 어떠한 모델도 강제하지 않습니다.

In order to fit a thin-plate spline, the data analyst must select a level of smoothness.

thin-plate spline을 적용하기 위해, 데이터 분석가는 부드러움의 수준을 선택해야 합니다.

Of the many methods that we examine in this book, some are less flexible, or more restrictive, in the sense that they can produce just a relatively small range of shapes to estimate f.

이 책에서 살펴보는 많은 방법들 중 일부는 f를 추정하기 위해 상대적으로 작은 범위의 형태만을 생성할 수 있다는 점에서 덜 유연하거나 더 제한적입니다.

It is also more interpretable than linear regression, because in the final model the response variable will only be related to a small subset of the predictors—namely, those with nonzero coefficient estimates.

또한 선형 회귀보다 해석하기 쉬운데, 이는 최종 모델에서 반응 변수가 예측 변수의 작은 부분집합, 즉 0이 아닌 계수 추정치를 가진 것들과만 관련되기 때문입니다.

Surprisingly, this is not always the case!

놀랍게도, 이것이 항상 그런 것은 아닙니다!

This phenomenon, which may seem counterintuitive at first glance, has to do with the potential for overfitting in highly flexible methods.

처음 보기에는 직관에 반하는 것처럼 보일 수 있는 이 현상은 매우 유연한 방법에서 과적합(overfitting)의 가능성과 관련이 있습니다.

In this example, this wouldn’t actually help speed anyway, for many reasons, but treat this as a toy model of wanting to JIT-compile the update of model parameters, where `jax.jit` makes an enormous difference.

이 예시에서는 여러 이유로 실제로 속도를 향상시키지는 못하지만, 이것을 모델 매개변수의 업데이트를 JIT 컴파일하고자 하는 장난감 모델로 취급하세요, 여기서 `jax.jit` 는 엄청난 차이를 만듭니다.

This won’t do.

이렇게 하면 안 됩니다.

Part of the problem with our counter was that the returned value didn’t depend on the arguments, meaning a constant was “baked into” the compiled output.

우리 카운터의 문제점 중 일부는 반환된 값이 인수에 의존하지 않아 컴파일된 출력에 상수가 "내장되었다"는 것이었습니다.

The most important difference, and in some sense the root of all the rest, is that JAX is designed to be functional, as in functional programming.

가장 중요한 차이점이자, 어떤 의미에서 모든 다른 차이의 근원은 JAX가 함수형 프로그래밍처럼 함수형으로 설계되었다는 것입니다.

This is because any such side-effects will only be executed once, when the python version of the function is run during compilation.

이는 그러한 side-effect가 컴파일 중에 파이썬 버전의 함수가 실행될 때 단 한 번만 실행되기 때문입니다.

Part of the problem with our counter was that the returned value didn’t depend on the arguments, meaning a constant was “baked into” the compiled output.

우리 카운터의 문제점 중 일부는 반환된 값이 인수에 의존하지 않아 컴파일된 출력에 상수가 "내장되었다"는 것이었습니다.

Notice that the need for a class becomes less clear once we have rewritten it this way. We could just keep `stateless_method`, since the class is no longer doing any work. This is because, like the strategy we just applied, object-oriented programming (OOP) is a way to help programmers understand program state.

이렇게 다시 작성하면 클래스의 필요성이 덜 명확해집니다. 클래스가 더 이상 작업을 수행하지 않기 때문에 `stateless_method`만 유지할 수 있습니다. 이는 우리가 방금 적용한 전략과 마찬가지로, 객체 지향 프로그래밍(OOP)이 프로그래머가 프로그램 상태를 이해하는 데 도움을 주는 방법이기 때문입니다.

Here, we only deal with one kind of state: the model parameters. But generally, you’ll see many kinds of state being threaded in and out of JAX functions, like optimizer state, layer statistics for batchnorm, and others.

여기서는 모델 매개변수라는 한 종류의 상태만 다룹니다. 하지만 일반적으로 JAX functions, optimizer state, batchnorm을 위한 layer statistics 등과 같은 여러 종류의 상태가 JAX 함수에 들어가고 나오는 것을 볼 수 있습니다.

Are we supposed to initialize them all manually, essentially repeating what we already write in the forward pass definition?

우리는 기본적으로 순방향 패스 정의에서 이미 작성한 것을 반복하면서 모두 수동으로 초기화해야 하는 것인가요?

