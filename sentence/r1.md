At the beginning of the nineteenth century, the method of least squares was developed, implementing the earliest form of what is now known as linear regression.

19세기 초, least squares라는 방법이 개발되었으며, 이는 지금으로서는 linear regression으로 알려진 가장 초기의 형태를 구현했습니다.

In the 1940s, various authors put forth an alternative approach, logistic regression.

1940년대에 여러 저자들이 대안적인 접근 방식인 logistic regression을 제시했습니다.

However, they were almost exclusively linear methods because fitting non-linear relationships was computationally difficult at the time.

그러나 당시에는 non-linear 관계를 맞추는 것이 계산적으로 어려웠기 때문에 거의 대부분 linear 방법들이었습니다.

This has the potential to continue the transformation of the field from a set of techniques used and developed by statisticians and computer scientists to an essential toolkit for a much broader community.

이것은 통계학자들과 컴퓨터 과학자들이 사용하고 개발한 일련의 기술에서 훨씬 더 넓은 커뮤니티에 필수적인 도구 모음으로 분야를 계속 변화시킬 잠재력이 있습니다.

Its success derives from its comprehensive and detailed treatment of many important topics in statistical learning, as well as the fact that (relative to many upper-level statistics textbooks) it is accessible to a wide audience.

이 책의 성공은 통계 학습에서 중요한 많은 주제들을 종합적이고 상세하게 다루었다는 점과, 많은 상급 수준의 통계 교재들과 비교할 때 폭넓은 독자층에게 접근하기 쉽다는 사실에서 비롯됩니다.

The most obvious growth has involved the development of new and improved statistical learning approaches aimed at answering a range of scientific questions across a number of fields.

가장 명백한 발전은 다양한 분야에서 과학적 질문에 답하기 위해 새롭고 개선된 통계 학습 방법론의 개발에 관련되어 있습니다.

In the 1990s, increases in computational power generated a surge of interest in the field from non-statisticians who were eager to use cutting-edge statistical tools to analyze their data.

1990년대에는 컴퓨터 연산력의 증가가 비통계학자들 사이에서 관심을 불러일으켰고, 이들은 최신 통계 도구를 사용하여 데이터를 분석하는 데 열심이었습니다.

Unfortunately, the highly technical nature of these approaches meant that the user community remained primarily restricted to experts in statistics, computer science, and related fields with the training (and time) to understand and implement them.

유감스럽게도 이러한 접근법의 고도로 기술적인 성격 때문에 사용자 커뮤니티는 주로 통계학, 컴퓨터 과학, 관련 분야의 전문가들로 제한되었으며, 이들은 이를 이해하고 구현하기 위한 교육(및 시간)을 갖추고 있었습니다.

In recent years, new and improved software packages have significantly eased the implementation burden for many statistical learning methods.

최근 몇 년 동안 새롭고 개선된 소프트웨어 패키지들이 많은 통계 학습 방법들의 구현 부담을 크게 줄여주었습니다.

ISL is not intended to replace ESL, which is a far more comprehensive text both in terms of the number of approaches considered and the depth to which they are explored.

ISL은 ESL을 대체하기 위한 것이 아니며, ESL은 고려된 접근 방법의 수와 그들이 탐구된 깊이 면에서 훨씬 더 포괄적인 텍스트입니다.

In teaching these topics over the years, we have discovered that they are of interest to master’s and PhD students in fields as disparate as business administration, biology, and computer science, as well as to quantitatively-oriented upper-division undergraduates.

여러 해에 걸쳐 이러한 주제들을 가르치면서, 우리는 이들이 경영학, 생물학, 컴퓨터 과학과 같이 다양한 분야의 석사 및 박사 과정 학생들과, 정량적으로 지향하는 상급 학부생들에게도 관심을 끌고 있다는 것을 발견했습니다.

We believe that these students do not need a deep understanding of these aspects in order to become informed users of the various methodologies, and in order to contribute to their chosen fields through the use of statistical learning tools.

우리는 이러한 학생들이 다양한 방법론의 정보에 밝은 사용자가 되고, 통계 학습 도구를 사용하여 자신이 선택한 분야에 기여하기 위해 이러한 측면들에 대한 깊은 이해가 필요하지 않다고 믿습니다.

ISL is based on the following four premises.

ISL은 다음의 네 가지 전제에 기반을 두고 있습니다.

Many statistical learning methods are relevant and useful in a wide range of academic and non-academic disciplines, beyond just the statistical sciences.

많은 통계 학습 방법들은 통계 과학뿐만 아니라 광범위한 학문적 및 비학문적 분야에서도 관련성이 있고 유용합니다.

We believe that many contemporary statistical learning procedures should, and will, become as widely available and used as is currently the case for classical methods such as linear regression.

우리는 많은 현대 통계 학습 절차들이 선형 회귀와 같은 고전적 방법들처럼 현재와 같이 널리 이용 가능하고 사용될 것이라고 믿습니다.

As a result, rather than attempting to consider every possible approach (an impossible task), we have concentrated on presenting the methods that we believe are most widely applicable.

그 결과, 모든 가능한 접근 방법을 고려하는 것(불가능한 일)보다는, 우리가 가장 널리 적용 가능하다고 믿는 방법들을 제시하는 데 집중하였습니다.

This is a good example of an instance where having a conceptual viewpoint saves you a lot of work.

이는 개념적 관점이 있으면 많은 작업을 절약할 수 있는 좋은 예입니다.

In fact, AB may be defined when BA is not.

실제로 AB는 BA가 정의되지 않은 경우에 정의될 수 있습니다.

You have to be careful when multiplying matrices together, because things like commutativity and cancellation fail.

행렬을 곱할 때 주의해야 하는데, 교환법칙과 소거법칙과 같은 것들이 실패할 수 있습니다.

We begin by characterizing what we mean by an optimal value distribution.

최적의 가치 분포가 무엇을 의미하는지 특성화하는 것부터 시작합니다.

Without understanding all of the cogs inside the box, or the interaction between those cogs, it is impossible to select the best box.

상자 안의 모든 톱니바퀴들이나 그 톱니바퀴들 간의 상호작용을 이해하지 않고서는 최적의 상자를 선택하는 것이 불가능합니다.

We presume that the reader is interested in applying statistical learning methods to real-world problems.

우리는 독자가 실제 세계의 문제에 통계 학습 방법을 적용하는 데 관심이 있다고 가정합니다.

Many of the less computationally-oriented students who were initially intimidated by the labs got the hang of things over the course of the quarter or semester.

계산에 중점을 두지 않은 많은 학생들이 처음에는 lab에 겁을 먹었지만, 학기나 학기 동안 점차 일에 익숙해졌습니다.

However, the labs in ISL are self-contained, and can be skipped if the reader wishes to use a different software package or does not wish to apply the methods discussed to real-world problems.

그러나 ISL의 lab은 독립적으로 구성되어 있어, 독자가 다른 소프트웨어 패키지를 사용하길 원하거나 실제 세계의 문제에 논의된 방법들을 적용하고 싶지 않은 경우 건너뛸 수 있습니다.

This group includes scientists, engineers, data analysts, data scientists, and quants, but also less technical individuals with degrees in non-quantitative fields such as the social sciences or business.

이 그룹에는 과학자, 엔지니어, 데이터 분석가, 데이터 과학자, 퀀트뿐만 아니라 사회 과학이나 비즈니스와 같은 비정량적 분야의 학위를 가진 덜 기술적인 개인들도 포함됩니다.

In the rare cases in which these two uses for lower case normal font lead to ambiguity, we will clarify which use is intended.

이러한 두 가지 용도가 소문자 일반 폰트 사용에서 드물게 모호함을 초래하는 경우에는, 우리는 어떤 용도가 의도된 것인지 명확히 할 것입니다.

However, in a few instances it becomes too cumbersome to avoid it entirely.

그러나 몇몇 경우에는 완전히 피하는 것이 너무 번거로워집니다.

We then show how these methods can be used to fit non-linear additive models for which there is more than one input.

그런 다음 이러한 방법들을 하나 이상의 입력이 있는 비선형 가산 모델에 적용하는 방법을 보여줍니다.

These can be easily skipped by readers who do not wish to delve as deeply into the material, or who lack the mathematical background.

이들은 자료에 깊이 파고들고 싶지 않거나 수학적 배경이 부족한 독자들에 의해 쉽게 건너뛰어질 수 있습니다.

How on earth do you remember this?

이걸 어떻게 기억하나요?

This is a crucial component of the change-of-variables formula in multivariable calculus.

이것은 다변수 미적분에서 변수 변환 공식의 중요한 구성 요소입니다.

This is even true for curvy shapes, in the following sense.

이것은 다음과 같은 의미에서 곡선 모양에도 마찬가지로 적용됩니다.

Let S be the unit disk in $R^2$,

S를 $R^2$의 단위 원으로 두고,

JAX is laser-focused on program transformations and accelerator-backed NumPy, so we don’t include data loading or munging in the JAX library.

JAX는 프로그램 변환과 가속기 기반의 NumPy에 집중하고 있어, JAX 라이브러리에 데이터 로딩이나 가공을 포함하지 않습니다.

In other words, our goal is to develop an accurate model that can be used to predict sales on the basis of the three media budgets.

다시 말해, 우리의 목표는 세 가지 미디어 예산을 기반으로 판매를 예측할 수 있는 정확한 모델을 개발하는 것입니다.

More generally, suppose that we observe a quantitative response $Y$ and $p$ different predictors, $X_1, X_2,...,X_p$.

보다 일반적으로, 우리가 정량적인 반응 $Y$와 $p$개의 다른 예측 변수들, $X_1, X_2,...,X_p$를 관찰한다고 가정해 봅시다.

The plot displays sales, in thousands of units, as a function of `TV`, `radio`, and `newspaper` budgets, in thousands of dollars, for 200 different markets.

이 그래프는 200개의 다른 시장에 대해, 수천 달러 단위의 `TV`, `radio`, `newspaper` 예산을 function으로 하는 수천 단위의 판매량을 보여줍니다.

@@@

In this setting, $\hat{f}$ is often treated as a *black box*, in the sense that one is not typically concerned with the exact form of $\hat{f}$, provided that it yields accurate predictions for $Y$.

이 상황에서, $\hat{f}$는 종종 *black box* 로 취급되며, 그것이 $Y$에 대한 정확한 예측을 제공한다면 $\hat{f}$의 정확한 형태에 대해 일반적으로 걱정하지 않는다는 의미에서 그렇습니다.

It is often the case that only a small fraction of the available predictors are substantially associated with $Y$. Identifying the few important predictors among a large set of possible variables can be extremely useful, depending on the application.

주로 사용 가능한 예측 변수들 중 극히 일부만이 $Y$와 실질적으로 연관되어 있습니다. 많은 가능한 변수들 중 몇 가지 중요한 예측 변수를 식별하는 것은 응용에 따라 매우 유용할 수 있습니다.

For instance, to what extent is the product’s price associated with sales?

예를 들어, 제품의 가격이 판매와 어느 정도 연관되어 있나요?

For example, in a real estate setting, one may seek to relate values of homes to inputs such as crime rate, zoning, distance from a river, air quality, schools, income level of community, size of houses, and so forth.

예를 들어 부동산 상황에서, 주택 가치를 범죄율, 구역 지정, 강으로부터의 거리, 공기 질, 학교, 지역사회의 소득 수준, 주택 크기 등과 같은 입력 값과 연관시키려 할 수 있습니다.

This enables planning to be interrupted or redirected at any time with little wasted computation, which appears to be a key requirement for efficiently intermixing planning with acting and with learning of the model.

이렇게 하면 낭비되는 계산량이 거의 없이 언제든 계획을 수행하는 중간에 끼어들거나 진행 방향을 바꿀 수 있다. 이것은 계획을 행동 및 모델에 대한 학습과 효과적으로 혼합하기 위한 핵심 요구조건인 것처럼 보인다.

Because planning proceeds incrementally, it is trivial to intermix planning and acting.

계획이 점증적으로 진행되기 때문에, 계획과 행동을 혼합하는 것은 식은 죽 먹기다.

This tends to happen when the model is optimistic in the sense of predicting greater reward or better state transitions than are actually possible.

실제로 가능한 것보다 더 큰 보상 또는 더 좋은 상태 전이를 예측한다는 측면에서 모델이 긍정적일 경우 이러한 상황이 발생하는 경향이 있다.

This encourages the agent to keep testing all accessible state transitions and even to find long sequences of actions in order to carry out such tests.

이것은 학습자로 하여금 접근 가능한 모든 상태 전이에 대해 계속 테스트하고, 심지어는 그러한 테스트를 수행하기 위해 행동의 긴 나열을 찾도록 장려한다.

As planning progresses, the region of useful updates grows, but planning is still far less efficient than it would be if focused where it would do the most good.

계획이 진행됨에 따라 유용한 갱신의 영역은 커지지만, 계획 자체는 계획이 가장 잘 수행되는 곳에 초점을 맞추었을 때보다 여전히 훨씬 더 비효율적이다.

In the much larger problems that are our real objective, the number of states is so large that an unfocused search would be extremely inefficient.

이 책의 진정한 목표인 훨씬 더 규모가 큰 문제에서는 상태의 개수가 상당히 많아서 초점 없는 탐색이 극도로 비효율적일 것이다.

In this way one can work backward from arbitrary states that have changed in value, either performing useful updates or terminating the propagation. This general idea might be termed *backward focusing* of *planning computations*.

이러한 방식으로 가치가 변한 임의의 상태로부터 역방향으로 진행할 수 있다. 이 과정에서 유용한 갱신을 할 수도 있고 진행을 멈출 수도 있다. 이러한 일반적인 개념을 이름하여 계획 계산(planning computation)의 역행 초점(backward focusing)이라고 부를 수도 있다.

Sample updates can win because they break the overall backing-up computation into smaller pieces—those corresponding to individual transitions—which then enables it to be focused more narrowly on the pieces that will have the largest impact. This idea was taken to what may be its logical limit in the “small backups” introduced by van Seijen and Sutton (2013).

표본 갱신이 전체 보강 계산을 개별 전이 각각에 해당하는 더 작은 조각으로 나눔으로써 가장 큰 영향력이 있는 조각들에 더 좁게 초점을 맞출 수 있도록 하기 때문에 표본 갱신의 성능이 더 좋을 수 있다. 이 개념은 반 세이젠과 서튼(2013)이 소개한 '작은 보강'에서 그 개념의 논리적 한계일 수도 있는 것에 적용되었다.

For example, another would be to focus on states according to how easily they can be reached from the states that are visited frequently under the current policy, which might be called *forward focusing*.

예를 들어, 또 다른 전략은 현재 정책하에서 자주 마주치는 상태로부터 얼마나 쉽게 그 상태에 도달할 수 있는지에 따라 상태에 초점을 두는 것이다. 이러한 전략을 순행(forward focusing)이라고 부를 수도 있다.

You can notice the first difference if you check the type of `x`. It is a variable of type `Array`, which is the way JAX represents arrays.

x의 타입을 확인하면 첫 번째 차이점을 알 수 있습니다. `x`는 `Array` 타입의 변수로, 이는 JAX가 배열을 나타내는 방식입니다.

The returned array is therefore not necessarily ‘filled in’ as soon as the function returns. Thus, if we don’t require the result immediately, the computation won’t block Python execution.

따라서 반환된 배열은 함수가 반환되자마자 반드시 '채워진' 상태는 아닙니다. 그러므로 결과가 즉시 필요하지 않다면, 계산이 Python 실행을 차단하지 않을 것입니다.

In addition to wanting to log the value, we often want to report some intermediate results obtained in computing the loss function.

값을 기록하고 싶은 것 외에도, 우리는 종종 손실 함수를 계산하는 과정에서 얻은 중간 결과를 보고하고 싶어 합니다.

The most important difference, and in some sense the root of all the rest, is that JAX is designed to be functional, as in functional programming.

가장 중요한 차이점이자, 어떤 의미에서 모든 다른 차이의 근원은 JAX가 함수형 프로그래밍과 같이 함수형으로 설계되었다는 것입니다.

The reason behind this is that the kinds of program transformations that JAX enables are much more feasible in functional-style programs.

이것의 이유는 JAX가 가능하게 하는 프로그램 변환의 종류가 함수형 스타일의 프로그램에서 훨씬 더 실현 가능하기 때문입니다.

However, as we will explain in the next guide, JAX computations are often compiled before being run using another program transformation, `jax.jit`.

하지만, 다음 가이드에서 설명하겠지만, JAX 계산은 종종 실행되기 전에 다른 프로그램 변환인 `jax.jit`를 사용하여 컴파일됩니다.

If we don’t use the old array after modifying it ‘in place’ using indexed update operators, the compiler can recognise that it can in fact compile to an in-place modify, resulting in efficient code in the end.

인덱스 업데이트 연산자를 사용하여 '현장에서' 수정한 후 이전 배열을 사용하지 않으면, 컴파일러는 실제로 현장에서의 수정으로 컴파일할 수 있다는 것을 인식하여, 결국 효율적인 코드를 생성할 수 있습니다.

We will explain other places where the JAX idiosyncrasies become relevant as they come up.

JAX의 특이한 점이 등장하는 대로 관련성이 있는 다른 곳에 대해 설명해 드리겠습니다.

The main difference between this example and real training loops is the simplicity of our model: that allows us to use a single array to house all our parameters.

이 예시와 실제 훈련 루프 사이의 주된 차이점은 우리 모델의 단순성입니다: 이것은 모든 매개변수를 하나의 배열에 담을 수 있게 해줍니다.

The (algebraic) multiplicity of an eigenvalue λ is its multiplicity as a root of the characteristic polynomial.

고유값 λ의 (대수적) 중복도는 특성 다항식의 근으로서의 중복도입니다.

It's easy to factor quadratic polynomials.

이차 다항식을 인수분해하는 것은 쉽습니다.

First we talked about the geometry of eigenvalues and eigenvectors.

먼저 고유값과 고유벡터의 기하학에 대해 이야기했습니다.

Instead they seek an estimate of $f$ that gets as close to the data points as possible without being too rough or wiggly.

대신에, 너무 거칠거나 흔들리지 않으면서 가능한 한 데이터 포인트에 가까운 $f$의 추정치를 찾으려 합니다.

This approach does not impose any pre-specified model on $f$.

이 접근법은 $f$에 사전에 지정된 어떠한 모델도 강제하지 않습니다.

In order to fit a thin-plate spline, the data analyst must select a level of smoothness.

thin-plate spline을 적용하기 위해, 데이터 분석가는 부드러움의 수준을 선택해야 합니다.

Of the many methods that we examine in this book, some are less flexible, or more restrictive, in the sense that they can produce just a relatively small range of shapes to estimate f.

이 책에서 살펴보는 많은 방법들 중 일부는 f를 추정하기 위해 상대적으로 작은 범위의 형태만을 생성할 수 있다는 점에서 덜 유연하거나 더 제한적입니다.

It is also more interpretable than linear regression, because in the final model the response variable will only be related to a small subset of the predictors—namely, those with nonzero coefficient estimates.

또한 선형 회귀보다 해석하기 쉬운데, 이는 최종 모델에서 반응 변수가 예측 변수의 작은 부분집합, 즉 0이 아닌 계수 추정치를 가진 것들과만 관련되기 때문입니다.

Surprisingly, this is not always the case!

놀랍게도, 이것이 항상 그런 것은 아닙니다!

This phenomenon, which may seem counterintuitive at first glance, has to do with the potential for overfitting in highly flexible methods.

처음 보기에는 직관에 반하는 것처럼 보일 수 있는 이 현상은 매우 유연한 방법에서 과적합(overfitting)의 가능성과 관련이 있습니다.

In this example, this wouldn’t actually help speed anyway, for many reasons, but treat this as a toy model of wanting to JIT-compile the update of model parameters, where `jax.jit` makes an enormous difference.

이 예시에서는 여러 이유로 실제로 속도를 향상시키지는 못하지만, 이것을 모델 매개변수의 업데이트를 JIT 컴파일하고자 하는 장난감 모델로 취급하세요, 여기서 `jax.jit` 는 엄청난 차이를 만듭니다.

This won’t do.

이렇게 하면 안 됩니다.

Part of the problem with our counter was that the returned value didn’t depend on the arguments, meaning a constant was “baked into” the compiled output.

우리 카운터의 문제점 중 일부는 반환된 값이 인수에 의존하지 않아 컴파일된 출력에 상수가 "내장되었다"는 것이었습니다.

The most important difference, and in some sense the root of all the rest, is that JAX is designed to be functional, as in functional programming.

가장 중요한 차이점이자, 어떤 의미에서 모든 다른 차이의 근원은 JAX가 함수형 프로그래밍처럼 함수형으로 설계되었다는 것입니다.

This is because any such side-effects will only be executed once, when the python version of the function is run during compilation.

이는 그러한 side-effect가 컴파일 중에 파이썬 버전의 함수가 실행될 때 단 한 번만 실행되기 때문입니다.

Part of the problem with our counter was that the returned value didn’t depend on the arguments, meaning a constant was “baked into” the compiled output.

우리 카운터의 문제점 중 일부는 반환된 값이 인수에 의존하지 않아 컴파일된 출력에 상수가 "내장되었다"는 것이었습니다.

Notice that the need for a class becomes less clear once we have rewritten it this way. We could just keep `stateless_method`, since the class is no longer doing any work. This is because, like the strategy we just applied, object-oriented programming (OOP) is a way to help programmers understand program state.

이렇게 다시 작성하면 클래스의 필요성이 덜 명확해집니다. 클래스가 더 이상 작업을 수행하지 않기 때문에 `stateless_method`만 유지할 수 있습니다. 이는 우리가 방금 적용한 전략과 마찬가지로, 객체 지향 프로그래밍(OOP)이 프로그래머가 프로그램 상태를 이해하는 데 도움을 주는 방법이기 때문입니다.

Here, we only deal with one kind of state: the model parameters. But generally, you’ll see many kinds of state being threaded in and out of JAX functions, like optimizer state, layer statistics for batchnorm, and others.

여기서는 모델 매개변수라는 한 종류의 상태만 다룹니다. 하지만 일반적으로 JAX functions, optimizer state, batchnorm을 위한 layer statistics 등과 같은 여러 종류의 상태가 JAX 함수에 들어가고 나오는 것을 볼 수 있습니다.

Are we supposed to initialize them all manually, essentially repeating what we already write in the forward pass definition?

우리는 기본적으로 순방향 패스 정의에서 이미 작성한 것을 반복하면서 모두 수동으로 초기화해야 하는 것인가요?

Greater difficulties arise when the environment changes to become better than it was before, and yet the formerly correct policy does not reveal the improvement. In these cases the modeling error may not be detected for a long time, if ever.

환경이 이전보다 개선되기 위해 바뀌었지만 이전에 올바른 정책이 개선된 점을 드러내지 않을 때 더 큰 어려움이 발생합니다. 이러한 경우 모델링 오류가 오랫동안 감지되지 않을 수 있습니다.

In a stochastic environment, variations in estimated transition probabilities also contribute to variations in the sizes of changes and in the urgency with which pairs need to be updated.

확률적 환경에서 추정된 전이 확률의 변화는 변화의 크기와 쌍을 업데이트해야 하는 긴급도의 변화에도 기여합니다.

The important feature of functional programming to grok when working with JAX is very simple: don’t write code with side-effects.

JAX를 사용할 때 이해해야 할 함수형 프로그래밍의 중요한 특징은 매우 간단합니다: side-effects가 있는 코드를 작성하지 마세요.

In this example, this wouldn’t actually help speed anyway, for many reasons, but treat this as a toy model of wanting to JIT-compile the update of model parameters, where `jax.jit` makes an enormous difference.

이 예시에서는 여러 이유로 실제로 속도를 향상시키지는 못하지만, 이것을 모델 매개변수의 업데이트를 JIT 컴파일하고자 하는 장난감 모델로 취급하세요, 여기서 `jax.jit`는 엄청난 차이를 만듭니다.

Implicit in that point of view is that expected updates, if possible, are preferable to sample updates.

이러한 관점에 내재된 생각은, 가능하기만 하다면 기댓값 갱신이 표본 갱신보다 더 선호할 만하다는 것이다.

The difference between these expected and sample updates is significant to the extent that the environment is stochastic, specifically, to the extent that, given a state and action, many possible next states may occur with various probabilities.

환경이 확률론적인 경우에 한해, 좀 더 분명히 말하면 상태와 행동이 주어졌을 때 가능성 있는 많은 다음 상태들이 다양한 확률로 발생할 수 있는 경우에 한해, 이러한 기댓값 갱신과 표본 갱신의 차이점은 중요한 의미를 갖는다.

The sample update is in addition affected by sampling error. On the other hand, the sample update is cheaper computationally because it considers only one next state, not all possible next states.

표본 갱신은 추가로 표본 오차에 의한 영향을 받는다. 반면에, 표본 오차는 가능한 모든 다음 상태가 아니라 오직 하나의 다음 상태만을 고려하기 때문에 많은 계산을 필요로 하지 않는다.

Given a unit of computational effort, is it better devoted to a few expected updates or to b times as many sample updates?

한 단위의 계산량이 몇 개의 기댓값 갱신에 사용되는 것이 좋은가? 아니면 개수가 b배인 표본 갱신에 사용되는 것이 좋은가?

For these cases, many state–action pairs could have their values improved dramatically, to within a few percent of the effect of an expected update, in the same time that a single state–action pair could undergo an expected update.

이 경우에 많은 수의 상태-행동 쌍들은 기댓값 갱신이 가치를 향상시키는 효과의 몇 퍼센트 이내로 그들의 가치를 극적으로 향상시킬 수 있었을 것이다. 하지만 이때 소요되는 시간은 고작 하나의 상태-행동 쌍이 기댓값 갱신을 수행하는 시간과 같은 시간이다.

