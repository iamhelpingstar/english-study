We then show how these methods can be used to fit non-linear additive models for which there is more than one input.

그런 다음 이러한 방법들을 하나 이상의 입력이 있는 비선형 가산 모델에 적용하는 방법을 보여줍니다.

These can be easily skipped by readers who do not wish to delve as deeply into the material, or who lack the mathematical background.

이들은 자료에 깊이 파고들고 싶지 않거나 수학적 배경이 부족한 독자들에 의해 쉽게 건너뛰어질 수 있습니다.

How on earth do you remember this?

이걸 어떻게 기억하나요?

This is a crucial component of the change-of-variables formula in multivariable calculus.

이것은 다변수 미적분에서 변수 변환 공식의 중요한 구성 요소입니다.

This is even true for curvy shapes, in the following sense.

이것은 다음과 같은 의미에서 곡선 모양에도 마찬가지로 적용됩니다.

Let S be the unit disk in $R^2$,

S를 $R^2$의 단위 원으로 두고,

JAX is laser-focused on program transformations and accelerator-backed NumPy, so we don’t include data loading or munging in the JAX library.

JAX는 프로그램 변환과 가속기 기반의 NumPy에 집중하고 있어, JAX 라이브러리에 데이터 로딩이나 가공을 포함하지 않습니다.

In other words, our goal is to develop an accurate model that can be used to predict sales on the basis of the three media budgets.

다시 말해, 우리의 목표는 세 가지 미디어 예산을 기반으로 판매를 예측할 수 있는 정확한 모델을 개발하는 것입니다.

More generally, suppose that we observe a quantitative response $Y$ and $p$ different predictors, $X_1, X_2,...,X_p$.

보다 일반적으로, 우리가 정량적인 반응 $Y$와 $p$개의 다른 예측 변수들, $X_1, X_2,...,X_p$를 관찰한다고 가정해 봅시다.

The plot displays sales, in thousands of units, as a function of `TV`, `radio`, and `newspaper` budgets, in thousands of dollars, for 200 different markets.

이 그래프는 200개의 다른 시장에 대해, 수천 달러 단위의 `TV`, `radio`, `newspaper` 예산을 function으로 하는 수천 단위의 판매량을 보여줍니다.

In this setting, $\hat{f}$ is often treated as a *black box*, in the sense that one is not typically concerned with the exact form of $\hat{f}$, provided that it yields accurate predictions for $Y$.

이 상황에서, $\hat{f}$는 종종 *black box* 로 취급되며, 그것이 $Y$에 대한 정확한 예측을 제공한다면 $\hat{f}$의 정확한 형태에 대해 일반적으로 걱정하지 않는다는 의미에서 그렇습니다.

It is often the case that only a small fraction of the available predictors are substantially associated with $Y$. Identifying the few important predictors among a large set of possible variables can be extremely useful, depending on the application.

주로 사용 가능한 예측 변수들 중 극히 일부만이 $Y$와 실질적으로 연관되어 있습니다. 많은 가능한 변수들 중 몇 가지 중요한 예측 변수를 식별하는 것은 응용에 따라 매우 유용할 수 있습니다.

For instance, to what extent is the product’s price associated with sales?

예를 들어, 제품의 가격이 판매와 어느 정도 연관되어 있나요?

For example, in a real estate setting, one may seek to relate values of homes to inputs such as crime rate, zoning, distance from a river, air quality, schools, income level of community, size of houses, and so forth.

예를 들어 부동산 상황에서, 주택 가치를 범죄율, 구역 지정, 강으로부터의 거리, 공기 질, 학교, 지역사회의 소득 수준, 주택 크기 등과 같은 입력 값과 연관시키려 할 수 있습니다.

This enables planning to be interrupted or redirected at any time with little wasted computation, which appears to be a key requirement for efficiently intermixing planning with acting and with learning of the model.

이렇게 하면 낭비되는 계산량이 거의 없이 언제든 계획을 수행하는 중간에 끼어들거나 진행 방향을 바꿀 수 있다. 이것은 계획을 행동 및 모델에 대한 학습과 효과적으로 혼합하기 위한 핵심 요구조건인 것처럼 보인다.

Because planning proceeds incrementally, it is trivial to intermix planning and acting.

계획이 점증적으로 진행되기 때문에, 계획과 행동을 혼합하는 것은 식은 죽 먹기다.

This tends to happen when the model is optimistic in the sense of predicting greater reward or better state transitions than are actually possible.

실제로 가능한 것보다 더 큰 보상 또는 더 좋은 상태 전이를 예측한다는 측면에서 모델이 긍정적일 경우 이러한 상황이 발생하는 경향이 있다.

Greater difficulties arise when the environment changes to become better than it was before, and yet the formerly correct policy does not reveal the improvement. In these cases the modeling error may not be detected for a long time, if ever.

환경이 이전의 환경보다 더 좋아지긴 했지만 형식적으로는 올바른 정책이 아직 향상되지 않았을 때 더 큰 어려움이 생긴다. 이 경우에는 모델링 오차가 있다면 이 오차가 오랫동안 감지되지 않을 수도 있다.

===

This encourages the agent to keep testing all accessible state transitions and even to find long sequences of actions in order to carry out such tests.

이것은 학습자로 하여금 접근 가능한 모든 상태 전이에 대해 계속 테스트하고, 심지어는 그러한 테스트를 수행하기 위해 행동의 긴 나열을 찾도록 장려한다.

As planning progresses, the region of useful updates grows, but planning is still far less efficient than it would be if focused where it would do the most good.

계획이 진행됨에 따라 유용한 갱신의 영역은 커지지만, 계획 자체는 계획이 가장 잘 수행되는 곳에 초점을 맞추었을 때보다 여전히 훨씬 더 비효율적이다.

In the much larger problems that are our real objective, the number of states is so large that an unfocused search would be extremely inefficient.

이 책의 진정한 목표인 훨씬 더 규모가 큰 문제에서는 상태의 개수가 상당히 많아서 초점 없는 탐색이 극도로 비효율적일 것이다.

In this way one can work backward from arbitrary states that have changed in value, either performing useful updates or terminating the propagation. This general idea might be termed backward focusing of planning computations.

이러한 방식으로 가치가 변한 임의의 상태로부터 역방향으로 진행할 수 있다. 이 과정에서 유용한 갱신을 할 수도 있고 진행을 멈출 수도 있다. 이러한 일반적인 개념을 이름하여 계획 계산(planning computation)의 역행 초점(backward focusing)이라고 부를 수도 있다.

In a stochastic environment, variations in estimated transition probabilities also contribute to variations in the sizes of changes and in the urgency with which pairs need to be updated.

확률론적 환경에서는, 전이 확률 추정값의 다양성이 변화의 크기 및 상태-행동 쌍이 갱신되어야 하는 시급성에 있어서 다양성을 야기한다.

Sample updates can win because they break the overall backing-up computation into smaller pieces—those corresponding to individual transitions—which then enables it to be focused more narrowly on the pieces that will have the largest impact. This idea was taken to what may be its logical limit in the “small backups” introduced by van Seijen and Sutton (2013).

표본 갱신이 전체 보강 계산을 개별 전이 각각에 해당하는 더 작은 조각으로 나눔으로써 가장 큰 영향력이 있는 조각들에 더 좁게 초점을 맞출 수 있도록 하기 때문에 표본 갱신의 성능이 더 좋을 수 있다. 이 개념은 반 세이젠과 서튼(2013)이 소개한 '작은 보강'에서 그 개념의 논리적 한계일 수도 있는 것에 적용되었다.

For example, another would be to focus on states according to how easily they can be reached from the states that are visited frequently under the current policy, which might be called *forward focusing*.

예를 들어, 또 다른 전략은 현재 정책하에서 자주 마주치는 상태로부터 얼마나 쉽게 그 상태에 도달할 수 있는지에 따라 상태에 초점을 두는 것이다. 이러한 전략을 순행(forward focusing)이라고 부를 수도 있다.

You can notice the first difference if you check the type of `x`. It is a variable of type `Array`, which is the way JAX represents arrays.

x의 타입을 확인하면 첫 번째 차이점을 알 수 있습니다. `x`는 `Array` 타입의 변수로, 이는 JAX가 배열을 나타내는 방식입니다.

The returned array is therefore not necessarily ‘filled in’ as soon as the function returns. Thus, if we don’t require the result immediately, the computation won’t block Python execution.

따라서 반환된 배열은 함수가 반환되자마자 반드시 '채워진' 상태는 아닙니다. 그러므로 결과가 즉시 필요하지 않다면, 계산이 Python 실행을 차단하지 않을 것입니다.

In addition to wanting to log the value, we often want to report some intermediate results obtained in computing the loss function.

값을 기록하고 싶은 것 외에도, 우리는 종종 손실 함수를 계산하는 과정에서 얻은 중간 결과를 보고하고 싶어 합니다.

가장 중요한 차이점이자, 어떤 의미에서 모든 다른 차이의 근원은 JAX가 함수형 프로그래밍과 같이 함수형으로 설계되었다는 것입니다.

The reason behind this is that the kinds of program transformations that JAX enables are much more feasible in functional-style programs.

이것의 이유는 JAX가 가능하게 하는 프로그램 변환의 종류가 함수형 스타일의 프로그램에서 훨씬 더 실현 가능하기 때문입니다.

The important feature of functional programming to grok when working with JAX is very simple: don’t write code with side-effects.

JAX를 사용할 때 이해해야 할 함수형 프로그래밍의 중요한 특징은 매우 간단합니다: 부작용이 있는 코드를 작성하지 마세요.

However, as we will explain in the next guide, JAX computations are often compiled before being run using another program transformation, `jax.jit`.

하지만, 다음 가이드에서 설명하겠지만, JAX 계산은 종종 실행되기 전에 다른 프로그램 변환인 `jax.jit`를 사용하여 컴파일됩니다.

If we don’t use the old array after modifying it ‘in place’ using indexed update operators, the compiler can recognise that it can in fact compile to an in-place modify, resulting in efficient code in the end.

인덱스 업데이트 연산자를 사용하여 '현장에서' 수정한 후 이전 배열을 사용하지 않으면, 컴파일러는 실제로 현장에서의 수정으로 컴파일할 수 있다는 것을 인식하여, 결국 효율적인 코드를 생성할 수 있습니다.

We will explain other places where the JAX idiosyncrasies become relevant as they come up.

JAX의 특이한 점이 등장하는 대로 관련성이 있는 다른 곳에 대해 설명해 드리겠습니다.

The main difference between this example and real training loops is the simplicity of our model: that allows us to use a single array to house all our parameters.

이 예시와 실제 훈련 루프 사이의 주된 차이점은 우리 모델의 단순성입니다: 이것은 모든 매개변수를 하나의 배열에 담을 수 있게 해줍니다.

The (algebraic) multiplicity of an eigenvalue λ is its multiplicity as a root of the characteristic polynomial.

고유값 λ의 (대수적) 중복도는 특성 다항식의 근으로서의 중복도입니다.

It's easy to factor quadratic polynomials.

이차 다항식을 인수분해하는 것은 쉽습니다.

First we talked about the geometry of eigenvalues and eigenvectors.

먼저 고유값과 고유벡터의 기하학에 대해 이야기했습니다.

Instead they seek an estimate of $f$ that gets as close to the data points as possible without being too rough or wiggly.

대신에, 너무 거칠거나 흔들리지 않으면서 가능한 한 데이터 포인트에 가까운 $f$의 추정치를 찾으려 합니다.

This approach does not impose any pre-specified model on $f$.

이 접근법은 $f$에 사전에 지정된 어떠한 모델도 강제하지 않습니다.

In order to fit a thin-plate spline, the data analyst must select a level of smoothness.

thin-plate spline을 적용하기 위해, 데이터 분석가는 부드러움의 수준을 선택해야 합니다.

Of the many methods that we examine in this book, some are less fexible, or more restrictive, in the sense that they can produce just a relatively small range of shapes to estimate f.

Of the many methods that we examine in this book, some are less flexible, or more restrictive, in the sense that they can produce just a relatively small range of shapes to estimate f.

이 책에서 살펴보는 많은 방법들 중 일부는 f를 추정하기 위해 상대적으로 작은 범위의 형태만을 생성할 수 있다는 점에서 덜 유연하거나 더 제한적입니다.

It is also more interpretable than linear regression, because in the final model the response variable will only be related to a small subset of the predictors—namely, those with nonzero coefficient estimates.

또한 선형 회귀보다 해석하기 쉬운데, 이는 최종 모델에서 반응 변수가 예측 변수의 작은 부분집합, 즉 0이 아닌 계수 추정치를 가진 것들과만 관련되기 때문입니다.

Surprisingly, this is not always the case!

놀랍게도, 이것이 항상 그런 것은 아닙니다!

This phenomenon, which may seem counterintuitive at first glance, has to do with the potential for overfitting in highly flexible methods.

처음 보기에는 직관에 반하는 것처럼 보일 수 있는 이 현상은 매우 유연한 방법에서 과적합(overfitting)의 가능성과 관련이 있습니다.

In this example, this wouldn’t actually help speed anyway, for many reasons, but treat this as a toy model of wanting to JIT-compile the update of model parameters, where `jax.jit` makes an enormous difference.

이 예시에서는 여러 이유로 실제로 속도를 향상시키지는 못하지만, 이것을 모델 매개변수의 업데이트를 JIT 컴파일하고자 하는 장난감 모델로 취급하세요, 여기서 `jax.jit` 는 엄청난 차이를 만듭니다.

This won’t do.

이렇게 하면 안 됩니다.

Part of the problem with our counter was that the returned value didn’t depend on the arguments, meaning a constant was “baked into” the compiled output.

우리 카운터의 문제점 중 일부는 반환된 값이 인수에 의존하지 않아 컴파일된 출력에 상수가 "내장되었다"는 것이었습니다.

The most important difference, and in some sense the root of all the rest, is that JAX is designed to be functional, as in functional programming.

가장 중요한 차이점이자, 어떤 의미에서 모든 다른 차이의 근원은 JAX가 함수형 프로그래밍처럼 함수형으로 설계되었다는 것입니다.

This is because any such side-effects will only be executed once, when the python version of the function is run during compilation.

이는 그러한 side-effect가 컴파일 중에 파이썬 버전의 함수가 실행될 때 단 한 번만 실행되기 때문입니다.

In this example, this wouldn’t actually help speed anyway, for many reasons, but treat this as a toy model of wanting to JIT-compile the update of model parameters, where jax.jit makes an enormous difference.

이 예시에서는 여러 이유로 실제로 속도를 향상시키지는 못하지만, 이것을 모델 매개변수의 업데이트를 JIT 컴파일하고자 하는 장난감 모델로 취급하세요, 여기서 jax.jit는 엄청난 차이를 만듭니다.

Part of the problem with our counter was that the returned value didn’t depend on the arguments, meaning a constant was “baked into” the compiled output.

우리 카운터의 문제점 중 일부는 반환된 값이 인수에 의존하지 않아 컴파일된 출력에 상수가 "내장되었다"는 것이었습니다.

Notice that the need for a class becomes less clear once we have rewritten it this way. We could just keep `stateless_method`, since the class is no longer doing any work. This is because, like the strategy we just applied, object-oriented programming (OOP) is a way to help programmers understand program state.

이렇게 다시 작성하면 클래스의 필요성이 덜 명확해집니다. 클래스가 더 이상 작업을 수행하지 않기 때문에 `stateless_method`만 유지할 수 있습니다. 이는 우리가 방금 적용한 전략과 마찬가지로, 객체 지향 프로그래밍(OOP)이 프로그래머가 프로그램 상태를 이해하는 데 도움을 주는 방법이기 때문입니다.

Here, we only deal with one kind of state: the model parameters. But generally, you’ll see many kinds of state being threaded in and out of JAX functions, like optimizer state, layer statistics for batchnorm, and others.

여기서는 모델 매개변수라는 한 종류의 상태만 다룹니다. 하지만 일반적으로 JAX functions, optimizer state, batchnorm을 위한 layer statistics 등과 같은 여러 종류의 상태가 JAX 함수에 들어가고 나오는 것을 볼 수 있습니다.

Are we supposed to initialize them all manually, essentially repeating what we already write in the forward pass definition?

우리는 기본적으로 순방향 패스 정의에서 이미 작성한 것을 반복하면서 모두 수동으로 초기화해야 하는 것인가요?

